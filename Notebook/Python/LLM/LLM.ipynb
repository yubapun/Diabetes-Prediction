{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5fc4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup \n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "import multiprocessing\n",
    "import glob\n",
    "import traceback\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import regex as re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d56cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_2017_2021_df = pd.read_csv('final_ec_combined_cdoc.csv')\n",
    "\n",
    "oc_2017_2021_df = pd.read_csv('final_oc_combined_cdoc.csv')\n",
    "\n",
    "rc_2017_2021_df = pd.read_csv('RC_2017_2021_CDOC_CLEANED.csv')\n",
    "\n",
    "bc_2017_2021_df = pd.read_csv('final_bc_combined_cdoc.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4bb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Regular expression pattern for MMR\n",
    "\n",
    "pattern = r\"\"\" \n",
    "\\bMSI\\b | \n",
    "\\bMicrosatellite\\b | \n",
    "\\bMLH-1\\b | \n",
    "\\bMSH-2\\b |\n",
    "\\bMSH-6\\b |\n",
    "\\bPMS-2\\b |\n",
    "\\bMismatch\\s+repair\\b \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for breast cancer, TNBC\n",
    "pattern_tnbc = r\"\"\" \n",
    "\\bER\\b | \n",
    "\\bPR\\b | \n",
    "\\bHER2\\b | \n",
    "\\bc-erb-b2\\b |\n",
    "\\bcerbb2\\b \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3cbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_2017_2021_df['mmr_flag'] = ec_2017_2021_df['CDOC'].str.contains(pattern, flags=re.IGNORECASE | re.VERBOSE, case=False, regex=True, na=False)\n",
    "oc_2017_2021_df['mmr_flag'] = oc_2017_2021_df['CDOC'].str.contains(pattern, flags=re.IGNORECASE | re.VERBOSE, case=False, regex=True, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d06f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re for TNBC\n",
    "bc_2017_2021_df['mmr_flag'] = bc_2017_2021_df['CDOC'].str.contains(pattern_tnbc, flags=re.IGNORECASE | re.VERBOSE, case=False, regex=True, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233fa7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ec = ec_2017_2021_df[ec_2017_2021_df['mmr_flag'] == True]\n",
    "pos_oc = oc_2017_2021_df[oc_2017_2021_df['mmr_flag'] == True]\n",
    "#pos_rc = rc_2017_2021_df[rc_2017_2021_df['mmr_flag'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_bc = bc_2017_2021_df[bc_2017_2021_df['mmr_flag'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b77b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = pos_bc['PATIENT_IDENTIFIER'].nunique()\n",
    "cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in ss['CDOC'].tolist():\n",
    "    print(txt, '\\n' + '-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad86a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR PROCESS AMI OUTCOME\n",
    "\n",
    "# llama url\n",
    "llama3_url = \"10.18.212.70:30012\"\n",
    "\n",
    "# prompt to use as default\n",
    "default_sys_prompt = '''\n",
    "You are a clinical-text classifier. You will be given clinical notes and your job is to follow the rules stated in the user prompt. \n",
    "DO NOT MAKE ASSUMPTIONS ABOUT PROTEINS THAT ARE NOT MENTIONED. DO not fabricate or generate results.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968a30b",
   "metadata": {},
   "source": [
    "# FOR MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35dc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dialog(CDOC, PATIENT_IDENTIFIER):\n",
    "  \n",
    "    dialog = [\n",
    "        [{\"role\": \"system\", \"content\": default_sys_prompt},\n",
    "         {\"role\": \"user\", \"content\": f''' \n",
    "         \n",
    "         Task: Detect wheter patients have an abnormal expression of DNA mismatch reapir (MMR) proteins: MLH-1, \n",
    "         MSH-2, MSH-6 or PMS-2 from the clinical notes.\n",
    "         \n",
    "         Clinical Note: {CDOC}\n",
    "         \n",
    "         **KEY PRINCIPLE**\n",
    "         1. LOOKOUT FOR THE FOLLOWING KEYWORDS:\n",
    "             - MSI High\n",
    "             - Mircostatellite unstable\n",
    "             - MLH-1 = Negative\n",
    "             - MSH-2 = Negative\n",
    "             - MSH-6 = Negative\n",
    "             - PMS-2 = Negative \n",
    "             - Negative expression of DNA mismatch repair proteins\n",
    "        \n",
    "         **CLASSIFICATION CRITERIA**\n",
    "         1. If Keywords specified above are found do the following: \n",
    "             - If there is an abnormal or negative expression, indicate overall_result as \"abnormal\".\n",
    "             - If the report indicates that the MMR expression is normal OR all the proteins are normal, indicate the overall result as \"normal\".\n",
    "             - if there are only equivocal and/or normal proteins, indicate the overall result as \"equivocal\"\n",
    "             - if the report has no mentions of keywords, DNA mismatch repairs or any of the proteins, return \"null\".\n",
    "        \n",
    "         2. IF KEYWORDS ARE NOT FOUND:\n",
    "            - Return overall_result as null since it has no correlation to the proteins. \n",
    "            - Examples: Random alpha-numeric values \"CECnnnnn\" where n is a numeric value. \n",
    "            - Rows with names or time does not equate to abnormal cases.\n",
    "            - Do not infer standalone words like \"yes\", \"as above\", Absent\" or \"Present\", \"False\", \"True\" unless directly following one of the protein names.\n",
    "            - If there is no mentions of DNA mismatch repairs or any of the proteins do not generate false results.\n",
    "    \n",
    "            Example 1:\n",
    "            {{\n",
    "                \"PMS-2\": \"normal\",\n",
    "                \"MLH-1\": \"abnormal\",\n",
    "                \"overall_result\": \"abnormal\"\n",
    "            }}\n",
    "\n",
    "            Example 2:\n",
    "            {{\n",
    "                \"PMS-2\": \"normal\",\n",
    "                \"MLH-1\": \"normal\",\n",
    "                \"overall_result\": \"normal\"\n",
    "            }}\n",
    "\n",
    "            Example 3:\n",
    "            {{\n",
    "                \"MLH-1\": \"normal\",\n",
    "                \"MSH-2\": \"normal\", \n",
    "                \"MSH-6\": \"equivocal\",\n",
    "                \"overall_result\": \"equivocal\"\n",
    "            }}\n",
    "\n",
    "             **Response Format: MANDATORY JSON**\n",
    "             {{\n",
    "                 \"overall_result\": abnormal|normal|equivocal|null,\n",
    "                 \"rationale\": \"short reasoning to justify overall_result\",\n",
    "                 \"supporting_text\": \"the snippet you matched\"\n",
    "             }}\n",
    "\n",
    "            Respond ONLY with the specific JSON format. Do not generate or fabricate results to justify the outcome. \n",
    "             \n",
    "            If there are medical terms like \"nursing\", \"multidisciplinary notes\", \"cancerline\" or any generic medical terminologies without any mentions of DNA mismatch repairs or any of the proteins flag as \"null\".  \n",
    "\n",
    "            DO NOT MAKE ASSUMPTIONS ABOUT PROTEINS THAT ARE NOT MENTIONED. \n",
    "            \n",
    "            IF NO PROTEINS IN THE KEYWORDS ARE FOUND IN {CDOC} SIMPLY STATE AS \"null\". \n",
    "            \n",
    "            IF alpha-numeric strings are found with no relation to the keywords in {CDOC} simply state as \"null\".\n",
    "            \n",
    "\n",
    "        '''}\n",
    "        ],\n",
    "    ]\n",
    "    return dialog \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21c71e",
   "metadata": {},
   "source": [
    "# FOR TNBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dialog(CDOC, PATIENT_PATIENT_IDENTIFIERKEY):\n",
    "  \n",
    "    dialog = [\n",
    "        [{\"role\": \"system\", \"content\": default_sys_prompt},\n",
    "         {\"role\": \"user\", \"content\": f''' \n",
    "         \n",
    "         Task: Detect wheter patients have negative expression of breast cancer markers ER, PR, and HER2 from the clinical notes.\n",
    "         HER2 may also be referred to as \"c-erb-b2\" or \"cerbb2\".\n",
    "         \n",
    "         Clinical Note: {CDOC}\n",
    "         \n",
    "         **KEY PRINCIPLE**\n",
    "         1. LOOKOUT FOR THE FOLLOWING KEYWORDS:\n",
    "             - ER = Negative\n",
    "             - PR = Negative\n",
    "             - HER2 = Negative\n",
    "             - c-erb-b2 = Negative\n",
    "             - cerbb2 = Negative\n",
    "        \n",
    "         **CLASSIFICATION CRITERIA**\n",
    "         1. If all 3 markers (ER, PR, HER2/c-erb-b2/cerbbb2) are reported as **negaive** in the same note:\n",
    "             - Indicate overall_result as \"triple_negative\"\n",
    "             \n",
    "         2. If one or more of the 3 markers are **not found**, or are reported as **positive**, or **unknown**, and the rest are negative:\n",
    "             - Indicate overall_result as \"not_triple_negative\"\n",
    "             \n",
    "         3. If there are no mentions of ER, PR, HER2, c-erb-b2, or cerbb2:\n",
    "             - Indicate overall_result as \"null\"\n",
    "\n",
    "             **Response Format: MANDATORY JSON**\n",
    "             {{\n",
    "                 \"overall_result\": triple_negative| not_triple_negative | null,\n",
    "                 \"rationale\": \"short reasoning to justify overall_result\",\n",
    "                 \"supporting_text\": \"the snippet you matched\"\n",
    "             }}\n",
    "\n",
    "            Respond ONLY with the specific JSON format. Do not generate or fabricate results to justify the outcome. \n",
    "             \n",
    "\n",
    "            DO NOT MAKE ASSUMPTIONS ABOUT RECEPTORS THAT ARE NOT MENTIONED. \n",
    "            \n",
    "            IF NO RECEPTORS ARE FOUND IN {CDOC} SIMPLY STATE AS \"null\". \n",
    "            \n",
    "            IF alpha-numeric strings are found with no relation to the keywords in {CDOC} simply state as \"null\".\n",
    "            \n",
    "\n",
    "        '''}\n",
    "        ],\n",
    "    ]\n",
    "    return dialog \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305fcfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama3_response(dialogs, llama3_url):\n",
    "    try:\n",
    "        connection = http.client.HTTPConnection(llama3_url, timeout = 60)\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "        payload = { \n",
    "            \"dialogs\": dialogs,\n",
    "            \"top_p\": 0.9, # default: 0.9\n",
    "            \"temperature\": 0.01, # default: 0.1\n",
    "            \"max_seq_len\": 8000, # default: 8192\n",
    "            \"max_gen_len\": 2000 # default: None, model stops when the stop symbol is generated\n",
    "        }\n",
    "        try:\n",
    "            connection.request(\"POST\", \"/batch-dialogs\", json.dumps(payload), headers)\n",
    "            response = connection.getresponse()\n",
    "            data = response.read().decode(\"utf-8\")\n",
    "            print(f\"Response sttus: {response.status}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Request failed: {str(e)}\")\n",
    "            return None\n",
    "        finally:\n",
    "            connection.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in API call: {e}\")\n",
    "        return None\n",
    "    \n",
    "def parse_response(data):\n",
    "    if data is None:\n",
    "        print(\"No data to parse\")\n",
    "        return None\n",
    "    try: \n",
    "        parsed_data = json.loads(data)\n",
    "        \n",
    "        if isinstance(parsed_data, list) and len(parsed_data) > 0:\n",
    "            first_item = parsed_data[0]\n",
    "            print(f\"First item: {first_item}\")\n",
    "            \n",
    "            if isinstance(first_item, dict) and 'generation' in first_item:\n",
    "                content = first_item['generation'].get('content', '')\n",
    "                content_dict = {\n",
    "                    'overall_result': \"\",\n",
    "                    'rationale': \"\",\n",
    "                    'supporting_text': \"\"\n",
    "                }\n",
    "                '''\n",
    "                if 'content' in gen:\n",
    "                    return {\n",
    "                        'overall_result': \"\",\n",
    "                        'rationale': gen['content'],\n",
    "                        'supporting_text': \"\"\n",
    "                    }\n",
    "                '''\n",
    "                lines = content.split('\\n')\n",
    "                for line in lines:\n",
    "                    try:\n",
    "                        line = line.strip()\n",
    "                        if '\"overall_result\":' in line:\n",
    "                            try:\n",
    "                                content_dict['overall_result'] = line.split(':', 1)[1].strip().strip('\"').rstrip(',')\n",
    "                            except:\n",
    "                                content_dict['overall_result'] = '' \n",
    "                        elif '\"rationale\":' in line:\n",
    "                            try:\n",
    "                                content_dict['rationale'] = line.split(':', 1)[1].strip().strip('\"').rstrip(',')\n",
    "                            except:\n",
    "                                content_dict['rationale'] = ''\n",
    "                        elif '\"supporting_text\":' in line:\n",
    "                            try:\n",
    "                                content_dict['supporting_text'] = line.split(':', 1)[1].strip().strip('\"').rstrip(',')\n",
    "                            except:\n",
    "                                content_dict['supporting_text'] = ''\n",
    "                    except Exception as line_error:\n",
    "                        print(f\"Error parsing response: {line_error}\")\n",
    "                        continue\n",
    "                print(f\"Parsed content: {content_dict}\")\n",
    "                return content_dict\n",
    "        print(f\"Unhandled response structure: {parsed_data}\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in parse_response: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "def process_in_batches(df, llama3_url, batch_size = 100, checkpoint_interval = 5000, start_row = 0):\n",
    "    \n",
    "    print(\"Starting process in batches function\")\n",
    "    if 'overall_result' not in df.columns:\n",
    "        df['overall_result'] = pd.Series(dtype = 'string')\n",
    "        df['rationale'] = pd.Series(dtype = 'string')\n",
    "        df['supporting_text'] = pd.Series(dtype = 'string')\n",
    "        \n",
    "    total_rows = len(df)\n",
    "    print(f\"Starting processing from row {start_row} out of {total_rows} total rows\")\n",
    "    \n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    print(\"starting main loop\")\n",
    "    \n",
    "    for start_idx in tqdm(range(start_row, total_rows, batch_size)):\n",
    "        print(f\"\\nStarting batch at index {start_idx}\")\n",
    "        end_idx = min(start_idx + batch_size, total_rows)\n",
    "        batch = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            print(f\"\\n Processing row {idx} (Patient key: {row['PATIENT_IDENTIFIER']})\")\n",
    "            try:\n",
    "                CDOC = row['CDOC'],\n",
    "                PATIENT_IDENTIFIER = row['PATIENT_IDENTIFIER'],\n",
    "                \n",
    "                dialog = construct_dialog(\n",
    "                    CDOC,\n",
    "                    PATIENT_IDENTIFIER\n",
    "                )\n",
    "                print(f\"Sending request for row {idx} to LLM... \")\n",
    "                response_data = get_llama3_response(dialog, llama3_url)\n",
    "                result = parse_response(response_data)\n",
    "                \n",
    "                if result:\n",
    "                    print(f\"Successfully processed row {idx}\")\n",
    "                    df.at[idx, 'overall_result'] = str(result['overall_result'])\n",
    "                    df.at[idx, 'rationale'] = str(result['rationale'])\n",
    "                    df.at[idx, 'supporting_text'] = str(result['supporting_text'])\n",
    "                    \n",
    "                \n",
    "                else:\n",
    "                    print(f\"No Valid result for row {idx}\")\n",
    "                    df.at[idx, 'overall_result'] = ''\n",
    "                    df.at[idx, 'rationale'] = f'error: No Valid result'\n",
    "                    df.at[idx, 'supporting_text'] = ''\n",
    "                    \n",
    "            except Exception as processing_error:\n",
    "                error_message = str(processing_error)\n",
    "                print(f\"Error processing row {idx}: {error_message}\")\n",
    "                df.at[idx, 'overall_result'] = ''\n",
    "                df.at[idx, 'rationale'] = f'error: {str(error_message)}'\n",
    "                df.at[idx, 'supporting_text'] = ''\n",
    "            time.sleep(0.1)\n",
    "                \n",
    "        print(f\"Debug - Strt idx: {start_idx}\")\n",
    "        print(f\"Debug - checkpoint interval: {checkpoint_interval}\")\n",
    "        print(f\"Debug - modulo result: {start_idx % checkpoint_interval}\")\n",
    "        \n",
    "        if start_idx > 0 and start_idx % checkpoint_interval == 0:\n",
    "            print(f\"Saving checkpoint at index {start_idx}\")\n",
    "                \n",
    "            checkpoint_df = df.copy()\n",
    "            try:\n",
    "                save_path = f'oc_final_count_v2_{start_idx}.csv'\n",
    "                print(f\"Debug - Attempting to save to: {save_path}\")\n",
    "                checkpoint_df.to_csv(save_path, index = False)\n",
    "                print(f\"Successfully saved checkpoint to {save_path}\")\n",
    "                print(f\"Current Data Types:\")\n",
    "                print(checkpoint_df[['overall_result', 'rationale', 'supporting_text']].dtypes)\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving checkpoints: {str(e)}\")\n",
    "                \n",
    "    print(f\"Saving final results at row {total_rows}\")\n",
    "    \n",
    "    try:\n",
    "        final_save_path = f'oc_final_count_v2_{total_rows}.csv'\n",
    "        print(f\"Saving to {final_save_path}\")\n",
    "        df.to_csv(final_save_path, index = False)\n",
    "        print(f\"Sucessfully saved final results\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final results: {e}\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "    \n",
    "def resume_from_checkpoint(checkpoint_path, new_df):\n",
    "    try:\n",
    "        checkpoint = pd.read_csv(checkpoint_path, dtype = {\n",
    "            'overall_result': 'string',\n",
    "            'rationale': 'string',\n",
    "            'supporting_text': 'string'\n",
    "        })\n",
    "        \n",
    "        last_processed = checkpoint['overall_result'].last_valid_index()\n",
    "        if last_processed is None:\n",
    "            return new_df, 0\n",
    "        \n",
    "        print(f\"Resuming from row {last_processed + 1}\")\n",
    "        return checkpoint, last_processed + 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {error}\")\n",
    "        return new_df, 0 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b33ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df = process_in_batches(pos_oc, llama3_url, batch_size = 100, checkpoint_interval = 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ec792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df, start_row = resume_from_checkpoint('tnbc_final_count_40000.csv', pos_bc)\n",
    "\n",
    "result_df = process_in_batches(df, llama3_url, batch_size = 100, checkpoint_interval = 20000, start_row = start_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
